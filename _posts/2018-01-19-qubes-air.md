---
layout: post
title: "Qubes Air: generalizing the Qubes architecture"
author: Joanna Rutkowska
---

The Qubes OS project has been around for nearly 8 years now, since its [original
announcement][initial_annoucement] back in April 2010 (and the actual origin
date can be traced back to November 11th, 2009, when an initial email
introducing this project was sent within ITL internally). Over these years Qubes
has achieved a reasonable success: according to our estimates it [has][stats]
nearly 30k regular users, which arguably could be considered a big success
given: 1) it is a new _OS_, rather than an _application_ which could be
installed on the user's favorite system, 2) it has introduced a (radically?)
[new approach][qubes_intro] to managing user digital life (i.e. the Explicit
Partitioning Model into security domains, aka _qubes_), and last but not least
3) has very [_specific_ hardware requirements][hcl] (which is a result of using
Xen as the hypervisor of choice, as well as Linux-based VMs for network- and
USB-hosting qubes).

Recent _years_ we have been working hard to bring you [Qubes 4.0][qubes40],
which features state-of-the-art technology not seen in the previous Qubes
versions, notably the next generation [Qubes Core Stack][core3_intro] and our
unique [Admin API][admin_api]. We believe this new platform (Qubes 4 represents
a major rewrite of the previous Qubes codebase!) paves the way to solve many of
the obstacles mentioned above.

But the new, flexible architecture of Qubes 4 will also open up new
possibilities and we've recently been thinking where and how should Qubes OS
evolve in the long term. In this article I discuss this vision. It should be
noted what I describe in this article has not been implemented yet.

## Why?

First, before we take a look at the long-term vision, it might be helpful to
understand why we would like to further evolve the Qubes architecture. Let us
quickly recap some of the most important weaknesses of the current Qubes OS
(including Qubes 4.0).

### Deployment cost (aka "how do I find Qubes compatible laptop?")

Probably the biggest problem with the current Qubes OS, which prevents its wider
adoption is the difficulty with finding a compatible laptop on which to install
it. Then, the whole process of needing to install a _new system_, rather than
just adding a new _application_ scares away many people. And it's hard to be
surprised by that.

This problem of deployment is not limited to Qubes OS, by the way.  It's just
that in case of Qubes OS these problems are significantly more pronounced,
because of the aggressive use of virtualization technology to isolate not just
apps, but also devices, as well as incompatibilities of Linux drivers with
modern hardware (something not inherent to Qubes OS architecture, but affecting
it nevertheless, since we use Linux-based VMs to handle devices).

### Hypervisor and virtualization as a single-point-of-failure

Speaking of virtualization technology, which has been the fundamental technology
used for the isolation of qubes ever since, there is another problem connected
with it. This is the problem of over-dependence on the hypervisor.  Over the
recent years, as more and more top notch researchers have looked into Xen, a
number of [security bugs][xen_bugs] have been discovered. Luckily,
[many][qubes_xsa_tracker] of them did not affect Qubes OS, but nevertheless
there is definitely too many that did :(

And the potential Xen bugs present just one, although arguably the most serious,
security problem. But other problems arise from the underlying architecture of
the x86 platform, where various inter-VM side- and covert-channels are made
possible thanks to aggressively optimized multi-core CPU architecture, most
spectacularly demonstrated by the recently published [Meltdown and Spectre
attacks][meltdown]. As well as even more fundamental problems of the underlying
hardware such as the [Row Hammer Attack][rowhammer] exists.

This leads us to a conclusion that, at least for some applications, we would
like to be able to achieve better isolation than the currently available
hypervisors _and_ popular hardware can provide.

## How?

One of the possible solutions to the above problems, which we discuss below, is
to "move Qubes to the cloud", however crazy this might sound at first. But
readers who are allergic to the notion of having their private computations
running in the (untrusted) cloud should not give up reading just yet -- rest
assured we will also discuss other solutions, not involving the cloud. The
beauty of this all is in the fact that, we believe, all these solutions are
largely isomorphic, from both the architecture, as well as the code, point of
view.

## Example: Qubes in the Cloud

Let's start with one important example for many of our customers: can we have
"Qubes in the Cloud"?

As I've been stressing multiple times, the essence of Qubes does not rest in the
Xen hypervisor, but rather in the concept of how various (so far mostly desktop)
workflows and apps [get decomposed][qubes_separation] into multiple containers,
which just happen to be implemented (currently) as Xen VMs. Consequently we can
easily imagine Qubes running on top of VMs which are hosted in some cloud, such
as Amazon EC2, Microsoft Azure Virtual Machines, or Google Compute Engine. This
is illustrated (in a very simplified way) on the diagram below:

![Simplified Qubes-as-a-Service scenario](/attachment/wiki/posts/qubes-cloud.png)

It should be clear that such a setup automatically eliminates the deployment
problem discussed above, as the user is no longer expected to perform any
installation steps herself -- instead can use Qubes-as-a-Service using just a
Web Browser or a mobile app. Admittedly sacrificing security if the endpoint
device used to access Qubes in the Cloud is not secure enough and/or privacy if
the cloud operator is not trustworthy enough.

But what do we really mean when we say "Qubes running on top of VMs"?

First and foremost, we want [Qubes Core Stack][core3_intro] connected to
whatever cloud management API, so that whenever the user executes, say,
`qvm-create` (or, more generally, issues any [Admin API][admin_api] call, in
this case `admin.vm.Create.*`) a new VM gets created and properly connected with
the Qubes infrastructure.

The above means that most (all?) Qubes Apps (e.g. Split GPG, PDF and image
converters, and many more), which are built around qrexec, should Just Work (TM)
when run on such "Qubes in the Cloud" setup.

Where things start to look less obvious is when we start to consider what should
constitute the Admin and GUI domains on such a cloud scenario? We will discuss
this in a section below.

## Example: the hybrid model

Some users might decide to run a subset of their qubes (perhaps some personal
ones) on their local laptop, while using the cloud only for some other VMs.
Another bonus of running some of the VMs locally would obviously be much better
GUI latency for the apps running there.

This ability to run some of the VMs locally, while others in the cloud, is what
I refer to as _Hybrid Mode_. The beauty of hybrid mode is that the user does not
need to be even aware (unless specifically interested!) whether the VM runs
locally or in the cloud. The Admin API, the qrexec services, even the GUI,
should all automatically handle both the cases. An exemplary hybrid model
configuration has been depicted on the diagram below.

An additional benefit of using a hybrid mode (which might also involve using
several cloud providers, not just one) is that we also solve the problem of
dependence on one isolation technology, e.g. on one specific hypervisor. Now, if
there is a fatal security bug discovered in one group of VMs (hosted under one
cloud service), it will not automatically affect isolation of other VM groups,
and especially the security boundary between these groups (later called
"zones").

![Qubes hybrid scenario](/attachment/wiki/posts/qubes-cloud-hybrid.png)

## Example: Qubes on "air-gapped" devices

We can go even further and let the user to use physically separate computers
(but, of course, connected with something like Ethernet link), such as Raspberry
PIs, or [USB Armory][usbarmory] as...  qubes (admittedly our new terminology,
i.e. _qubes_ instead of _AppVMs_ is more justified in this context).  Again,
this means the Admin API calls, qrexec services, and even GUI virtualization,
should all work across these qubes!

![Qubes with some qubes running on "air-gapped" devices](/attachment/wiki/posts/qubes-airgap.png)

This seems especially useful for hosting special services, such as e.g. [GPG
backend][SplitGPG] or password manager in such as physically separated VM. But,
of course, it should also be possible to run normal, GUI-based apps, such as an
office suite to work on some special projects. An interested reader might get
more inspirations in [this paper][qubes_separation].

Needless to say such "air-gapped" scenario allows yet another possibility to
work around potential security problems with virtualization and processors we
face today.

## Under the hood: introducing Qubes Zones

We've been thinking what changes to the current Qubes architecture, especially
to the [Qubes Core Stack][core3_intro], are necessary to make the scenarios
above easy (and elegant) to implement.

One such important new concept, which should make supporting all these scenarios
with a unified architecture, is what we decided to name **Qubes Zones**.

A **Zone** is a concept that combines several things together:

 - an underlying "isolation technology" which is used to implement qubes, which
   might, or might not, be VMs. E.g. they might also be Raspberry PI or USB
   Armory devices, or Amazon EC2 VMs, or Docker containers.

 - the inter-qubes communication technology. E.g. in case of qubes implemented
   as Xen-based VMs (as in current Qubes OS), the Xen-specific shared-memory
   based mechanism (so called Grant Tables) is used to implement the
   communication between qubes. In case of Raspberry PI devices Ethernet
   technology would likely be used. In case of Qubes running in the cloud, some
   form of cloud-provided networking will provide inter-qubes communication.
   Technically-wise, this is about how Qubes' vchan is implemented, as the
   qrexec layer should remain the same across all possible platforms.

 - A "local copy" of an _Admin qube_ (previously referred to as "AdminVM"), used
   mainly to orchestrate VMs and make policing decisions for all the qubes
   within the zone. This Admin qube can be either in "Master" or "Slave" mode,
   and there can only be one Admin qube running as Master across all the zones
   in _one Qubes system_.

 - Optionally, a "local copy" of _GUI qube_ (previously referred to as "GUI
   domain", or "GUIVM"). Like with Admin qubes, the GUI qube could be running in
   either Master or Slave mode. The user is expected to connect (e.g. with RDP
   protocol) or log into, only the GUI qube that runs in Master mode, which
   should be tasked with a job of combining all the GUI elements exposed via
   other GUI qubes (all of which must run in the Slave mode).

 - Some technology used to implement storage for the qubes running within the
   zone. E.g. in case of Qubes OS running under Xen, local disk is used to store
   VM images (more specifically, in Qubes 4.0 we use [Storage
   Pools][qubes_storage_pool] by default). In case of a zone composed of a
   cluster of multiple Raspberry PI or similar devices, the storage could be
   either: a bunch of micro-SD cards (each plugged into each device), or some
   network storage.

![Qubes Zones is the key new concept for Qubes Air](/attachment/wiki/posts/qubes-zones.png)

So far this is nothing radically new compared to what we have had in Qubes
already. Specifically ever since we have decided to abstract Qubes architecture
away from Xen-specific details -- an effort we codenamed [_Qubes
Odyssey_][qubes_odyssey], and which is now nearly complete.

What _is_ radically different is that we want now to allow more than one zone to
exist within _one_ Qubes system!

In order to support multiple zones, we need to provide transparent proxying of
qrexec services across the zones, so that a qube need not be aware that that
destination qubes it requests a service from might be residing in another zone.
This is the main reason we introduce multiple "local" Admin qubes in each zone
Slave Admin qubes are bridges which also allow the master Admin qube to manage
the whole system (e.g. request creation of new qubes, connecting and setting up
storage for these qubes, setting up networking between qubes, etc).

## Under the hood: qubes' interfaces

Within one zone there are multiple _qubes_. Let me stress one more time that the
term qube is very generic and does not imply and specific technology. It could
be a Virtual Machine (VM) under _some_ virtualization system, it could be some
kind of a container, or a physically separate computing device, such as e.g.
Raspberry PI- or Arduino-like device.

So what essential features are needed to make a _qube_?  There are a few
requirements which we discuss now:

 1. A qube should implement a [vchan endpoint][vchan]. The actual technology on
    top of which this will be implemented -- whether some shared memory within a
    virtualization or containerizastion system, TCP/IP, or [something
    else](https://tools.ietf.org/html/rfc1149) -- will be specific to the kind
    of zone that it is to support, of course.

 2. Taking this further, a _qube_ should also implement a [qrexec] endpoint,
    although this should be very straitforward, given point #1 above is already
    satified (i.e. vchan endpoint implemention exists). This ensures most (all?)
    qrexec services, which are the basis for most of the intergation, apps and
    services we have created for Qubes, should Just Work(TM).

 3. Optionally, for some qubes, a GUI endpoint should also be implemented (see
    the discussion below).
 
 4. In order to be compatible with Qubes [networking], a qube should expect
    _one_ uplink network interface (to be exposed by whatever management
    technology specific to the particular zone), and (optionally) multiple
    downlink network interfaces (if it is to work as a proxy qube, e.g. VPN or
    firewalling qube).

 5. Finally, a qube should expect two kinds volumes to be exposed by the
    zone-specific management stack:
     - one read-only, which is intended to be used as a root filesystem by the
       qube (the managament stack might also expose an auxiliary volume for
       implementing copy-on-write illusion for the VM, like the ``volatile.img``
       we currently expose on Qubes),
     - and another read-writable, specific for this one qube only, and which is
       intended to be used as a home directory-like storage. This is, naturally,
       to allow implemention of Qubes [templates], a mechanism which we believe
       brings not only lots of convenience but also some [security
       benefits][paranoid_backups].

## GUI virtualization considerations

Since [the very beginning][qubes_arch] Qubes has been envisioned as a system for
desktop computing (as opposed to servers). This has implied that the [GUI
virtualization][qubes_gui] has been part of the core Qubes infrastructure.

However, with some of the _security-optimized_ management infrastructure we have
added to Qubes OS recently, i.e. [Salt stack integration][qubes_salt] (which
significantly shrinks the attack surface onto the system TCB, compared to more
traditional "management" solutions) and the [Qubes Admin API][admin_api] (which
allows for fine-grained decomposition of the management roles), plus the deeply
integrated features such as [templates], we think Qubes Air might be useful also
in some non-desktop applications, such as in the embedded an appliance space and
possibly even on the server-/services-side. In this case, it makes perfect sense
to have qubes not implementing GUI protocol endpoints.

However, the primary area where Qubes excels, I still think, is on securing
desktop workflows. For these we need GUI ~~virtualization~~multiplexing and the
qubes need to implement GUI protocol endpoints. Below we discuss some
considerations for the trade-offs involved here.

The Qubes [GUI protocol][qubes_gui] has been optimized for security. This means
the protocol has been designed to be extremely simple, allowing for very simple
processing of the incoming packets, thus significantly limiting the attack
surface on the GUI daemon (which is usually considered trusted). The price we
pay for this security property is lack of various optimizations, such as
on-the-fly compression, which others protocols, such as VNC or RDP naturally
offer. So far we've been able to get away with these trade-offs, because in the
current Qubes the GUI protocol runs over Xen shared memory, and 1) DRAM is very
fast (i.e has low latency and super-high bandwidth), 2) the implementation on
Xen smartly makes use of page _sharing_ rather than memory _copying_, so that it
achieves near native speed (of course with a limitation that we don't expose GPU
functionalities to VMs, which might limit the experience in some graphical
applications anyway).

However, when qubes run on remote computers (e.g in the cloud) or on physically
separate computers (e.g. on a cluster of Raspberry PIs), we face a potential
problem of graphics performance. The solution we see is to introduce a local
copy of GUI qubes into each zone. Here we make an implicit assumption that
within one zone there should be available a significantly faster communication
channel between qubes, than between the zones (e.g. inter-VM communication
within one datacenter should be significantly faster than between the user's
laptop and the cloud). The Qubes GUI protocol is then used between qubes and the
local GUI qube within one zone, but some more efficient (yet more complex)
protocol is used to aggregate GUI into the master GUI qube from all the slave
GUI qubes. Thanks to such combined setup we still get a benefit of reasonably
secure GUI -- untrusted qubes still use Qubes secure GUI protocol to communicate
with the local GUI qube -- while also benefiting from better efficiency of
remote access-optimized protocols such as RDP or VNC to get GUI onto the user's
device over the network. (Here we make an implicit assumption that the local GUI
qubes are significantly more trustworthy than corresponding qubes. If that's not
the case _and_ if we also worry about the attacker, who compromised the local
slave GUI qube, to exploit a potential bug within VNC/RDP protocols and attack
the master GUI qube, we could still resort to the fine-grained Qubes Admin API
to limit the potential damage the attacker might gain.)

## Digression on apps "cloudification"

It's hard to not notice how the model of desktop applications have been
changing in the recent decade or so, where many of the standalone applications,
until recently running on desktop computers, now run in the cloud and have only
their frontends executed within a browser running on the client systems. How
does Qubes compartmentalization model, and more importantly Qubes being a
_desktop_ OS, deal with this change of apps paradigm?

Above we have discussed how it's possible to essentially move Qubes
standard VMs from the local desktop/laptop to the cloud (or physically separate
computers), while still preserving the Qubes look and feel, making it nearly
unnoticeable for the user where the actual qubes are running (whether locally or
remotely). I think it will be a great milestone when we finally get there, as it
will open up many new applications, as well as remove many obstacles that today
prevent easy deployment of Qubes OS (such as e.g. the need to find and maintain
dedicated laptops for Qubes OS).

But an important question which we should ask ourselves is how relevant this
model will be in the coming years? Even with the vision presented above, we
still consider standalone, classic desktop applications running in the VMs
(qubes). At the same time, the world seems to be moving towards the cloud-hosted
app-as-a-service model, exemplified by e.g. Google Docs or Microsoft Office 365.
How relevant the whole Qubes architecture, even the cloud-based variation
presented above, is for this new model of using "desktop" apps?

I'd like to argue that the Qubes architecture still makes perfect sense in this
new model.

First, it's probably easy to accept that there will always be payloads (i.e.
application) which users, both individual as well as corporate, will prefer (or
be forced) to run locally, or at least on some trusted servers (clouds). At the
same time, it's very likely that these same users will want to embrace the
general, public cloud with its multitude of apps-as-a-service options. Not
surprisingly there will be need how to isolate these workloads from interfering
with each other.

Some examples of payloads that are better suited to be hosted within traditional
applications (and consequently within qubes), are: MS Office for sensitive
documents, large data-processing applications, as well as networking and USB
drivers and stacks. The latter things might not be very visible to the user, but
nevertheless we can't really offload these to the cloud, and need to host on the
local machine, and all these networking and USB stacks present a huge attack
surface onto the other user applications.

What about isolating web apps from each other? As well as protecting the host
from them? Of course that's the primary task of the Web browser. Yet, despite
lots of effort put in by vendors, browser's security measures are still being
circumvented. Continued expansion of the APIs that modern browsers expose to the
Web application, such as e.g. [WebGL][webgl], suggests this state of affairs
might not improve significantly within foreseeable future.

Where Qubes model becomes useful, I think, is that it allows to put the whole
browser within a container that is isolated by stronger mechanisms (simply
because Qubes does not need to maintain all the interfaces that the browser
must) and is managed by Qubes-defined policies. It's rather natural to imagine
e.g. Chrome OS-based template for Qubes (perhaps even unikernel-based), from
which lightweight browser VMs could be created. Either on the user's local
machine, or... in the cloud, as described above. Again there will be pros and
cons of both approaches, but Qubes should support both and mostly seamlessly
from the user and admin point of view (as well Qubes service developer's point
of view!). And this all also seamless integrated with fully-fledged qubes
running either on user local machines (e.g. VMs) or in the cloud.

## Summary

Qubes Air is the next step on our roadmap to make the concept of "Security
through Compartmentalization" applicable to more scenarios. It also is an
attempt to address some of the biggest problems or weaknesses plaguing the
current Qubes implementation, specifically the problem of difficult deployment and the
problem of treating virtualization as a single-point-of-failure. While Qubes
Cloud is one natural application that could built on top of Qubes Air, it is by
far not the only one -- we have discussed Qubes over clusters of physically
isolated devices, as well as various hybrid scenarios. I believe the approach to
security which Qubes has been implementing for years now, will continue to be
valid for the years to come, even in the scenarios of apps-as-a-service.

[stats]: https://www.qubes-os.org/statistics/
[antiqubes]: https://twitter.com/zeynep/status/838428959167631360
[qubes_intro]: https://www.qubes-os.org/video-tours/
[hcl]: https://www.qubes-os.org/hcl/
[qubes40]: https://www.qubes-os.org/news/2017/07/31/qubes-40-rc1/
[initial_annoucement]: https://blog.invisiblethings.org/2010/04/07/introducing-qubes-os.html
[xen_bugs]: https://xenbits.xen.org/xsa/
[qubes_xsa_tracker]: https://www.qubes-os.org/security/xsa/
[meltdown]: https://meltdownattack.com/
[rowhammer]: https://googleprojectzero.blogspot.com/2015/03/exploiting-dram-rowhammer-bug-to-gain.html
[core3_intro]: https://www.qubes-os.org/news/2017/10/03/core3/
[admin_api]: https://www.qubes-os.org/news/2017/06/27/qubes-admin-api/
[vchan]: https://github.com/QubesOS/qubes-core-vchan-xen
[qrexec]: https://www.qubes-os.org/doc/qrexec3/
[qrexec_policy]: https://www.qubes-os.org/doc/qrexec3/#qubes-rpc-administration
[vdi]: https://en.wikipedia.org/wiki/Desktop_virtualization
[trustedexec]: https://blog.invisiblethings.org/2011/12/13/trusted-execution-in-untrusted-cloud.html
[privatecore]: https://privatecore.com/
[sgx_part2]: https://blog.invisiblethings.org/2013/09/23/thoughts-on-intels-upcoming-software.html
[qubes_storage_pool]: TODO
[qubes_odyssey]: https://blog.invisiblethings.org/2013/03/21/introducing-qubes-odyssey-framework.html
[networking]: https://blog.invisiblethings.org/2011/09/28/playing-with-qubes-networking-for-fun.html
[templates]: https://www.qubes-os.org/getting-started/#appvms-qubes-and-templatevms
[SplitGPG]: https://www.qubes-os.org/doc/split-gpg/
[qubes_arch]: https://www.qubes-os.org/attachment/wiki/QubesArchitecture/arch-spec-0.3.pdf
[qubes_gui]: https://www.qubes-os.org/doc/gui/
[qubes_salt]: https://www.qubes-os.org/news/2015/12/14/mgmt-stack/
[paranoid_backups]: https://www.qubes-os.org/news/2017/04/26/qubes-compromise-recovery/
[qubes_separation]: https://invisiblethingslab.com/resources/2014/Software_compartmentalization_vs_physical_separation.pdf
[usbarmory]: https://inversepath.com/usbarmory
